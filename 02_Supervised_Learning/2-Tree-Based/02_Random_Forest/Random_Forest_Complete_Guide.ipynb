{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2978d182",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> <strong>ðŸŒ² Random Forest - Complete Guide</strong> </h1>\n",
    "\n",
    "This notebook provides a comprehensive introduction to Random Forest, covering:\n",
    "- Conceptual foundation and ensemble learning\n",
    "- Implementation from scratch (simplified)\n",
    "- Scikit-learn implementation\n",
    "- Model evaluation and interpretation\n",
    "- Feature importance and out-of-bag scoring\n",
    "- Comparison with Decision Trees\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671ca57",
   "metadata": {},
   "source": [
    "## **ðŸ“š 1. Import Libraries and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                           mean_squared_error, r2_score, mean_absolute_error,\n",
    "                           precision_score, recall_score, f1_score)\n",
    "from sklearn.datasets import make_classification, make_regression, load_iris, load_wine, load_breast_cancer\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae8709",
   "metadata": {},
   "source": [
    "## **ðŸ§  2. Conceptual Foundation**\n",
    "\n",
    "### **What is Random Forest?** ðŸ¤”\n",
    "\n",
    "Random Forest is an **ensemble learning method** that combines multiple decision trees to create a more robust and accurate model. It uses two key techniques:\n",
    "\n",
    "1. **Bootstrap Aggregating (Bagging)**: Train each tree on a different subset of the data\n",
    "2. **Random Feature Selection**: Each tree considers only a random subset of features at each split\n",
    "\n",
    "### **How Random Forest Works:**\n",
    "\n",
    "1. **Bootstrap Sampling**: Create multiple bootstrap samples from the training data\n",
    "2. **Random Feature Selection**: For each tree, randomly select a subset of features\n",
    "3. **Train Multiple Trees**: Train a decision tree on each bootstrap sample\n",
    "4. **Aggregate Predictions**: \n",
    "   - **Classification**: Majority voting\n",
    "   - **Regression**: Average predictions\n",
    "\n",
    "### **Key Concepts:**\n",
    "\n",
    "- **Bagging**: Bootstrap Aggregating reduces variance\n",
    "- **Out-of-Bag (OOB) Error**: Use unused samples for validation\n",
    "- **Feature Importance**: Average importance across all trees\n",
    "- **Wisdom of Crowds**: Many weak learners create a strong learner\n",
    "\n",
    "### **Mathematical Foundation:**\n",
    "\n",
    "#### Bootstrap Sampling:\n",
    "For dataset $D$ with $n$ samples, create $B$ bootstrap samples $D_1, D_2, ..., D_B$ by sampling with replacement.\n",
    "\n",
    "#### Random Forest Prediction:\n",
    "**Classification:**\n",
    "$$\\hat{y} = \\text{mode}\\{h_1(x), h_2(x), ..., h_B(x)\\}$$\n",
    "\n",
    "**Regression:**\n",
    "$$\\hat{y} = \\frac{1}{B} \\sum_{i=1}^{B} h_i(x)$$\n",
    "\n",
    "#### Out-of-Bag Error:\n",
    "$$\\text{OOB Error} = \\frac{1}{n} \\sum_{i=1}^{n} L(y_i, \\hat{y}_i^{OOB})$$\n",
    "\n",
    "Where $\\hat{y}_i^{OOB}$ is the prediction for sample $i$ using only trees that didn't include $i$ in training.\n",
    "\n",
    "### **Why Random Forest Works:**\n",
    "\n",
    "1. **Reduces Overfitting**: Averaging reduces variance\n",
    "2. **Handles Missing Values**: Can work with incomplete data\n",
    "3. **Feature Importance**: Provides feature rankings\n",
    "4. **Parallel Training**: Trees can be trained independently\n",
    "5. **Robust to Outliers**: Averaging reduces impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5922d",
   "metadata": {},
   "source": [
    "## **ðŸ“Š 3. Generate Sample Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afad185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Classification Dataset with more complexity\n",
    "print(\"ðŸŽ¯ Creating Classification Dataset\")\n",
    "X_cls, y_cls = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_redundant=3,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Add feature names\n",
    "feature_names_cls = [f'feature_{i}' for i in range(X_cls.shape[1])]\n",
    "df_cls = pd.DataFrame(X_cls, columns=feature_names_cls)\n",
    "df_cls['target'] = y_cls\n",
    "\n",
    "print(f\"Classification dataset shape: {df_cls.shape}\")\n",
    "print(f\"Classes: {np.unique(y_cls)}\")\n",
    "print(f\"Class distribution: {np.bincount(y_cls)}\")\n",
    "\n",
    "# Regression Dataset\n",
    "print(\"\\nðŸ“ˆ Creating Regression Dataset\")\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=800,\n",
    "    n_features=8,\n",
    "    n_informative=5,\n",
    "    noise=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "feature_names_reg = [f'feature_{i}' for i in range(X_reg.shape[1])]\n",
    "df_reg = pd.DataFrame(X_reg, columns=feature_names_reg)\n",
    "df_reg['target'] = y_reg\n",
    "\n",
    "print(f\"Regression dataset shape: {df_reg.shape}\")\n",
    "\n",
    "# Load real datasets for comparison\n",
    "print(\"\\nðŸ· Loading Wine Dataset\")\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "print(f\"Wine dataset shape: {X_wine.shape}\")\n",
    "print(f\"Classes: {wine.target_names}\")\n",
    "print(f\"Features: {len(wine.feature_names)}\")\n",
    "\n",
    "# Visualize some relationships\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(df_cls['feature_0'], df_cls['feature_1'], c=y_cls, cmap='viridis', alpha=0.6)\n",
    "plt.xlabel('Feature 0')\n",
    "plt.ylabel('Feature 1')\n",
    "plt.title('Classification Dataset')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(df_reg['feature_0'], df_reg['target'], alpha=0.6, color='orange')\n",
    "plt.xlabel('Feature 0')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Regression Dataset')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X_wine[:, 0], X_wine[:, 1], c=y_wine, cmap='Set1', alpha=0.6)\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Malic Acid')\n",
    "plt.title('Wine Dataset')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa4e5f",
   "metadata": {},
   "source": [
    "## **ðŸ”§ 4. Random Forest from Scratch (Simplified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c75361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestScratch:\n",
    "    \"\"\"\n",
    "    Simplified Random Forest implementation for binary classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_depth=3, max_features='sqrt', random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.feature_importances_ = None\n",
    "        \n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \"\"\"Create bootstrap sample\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices], indices\n",
    "    \n",
    "    def _get_random_features(self, n_features):\n",
    "        \"\"\"Get random subset of features\"\"\"\n",
    "        if self.max_features == 'sqrt':\n",
    "            max_features = int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            max_features = int(np.log2(n_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            max_features = self.max_features\n",
    "        else:\n",
    "            max_features = n_features\n",
    "        \n",
    "        return np.random.choice(n_features, max_features, replace=False)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the random forest\"\"\"\n",
    "        if self.random_state:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Track feature usage for importance calculation\n",
    "        feature_usage = np.zeros(n_features)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Create bootstrap sample\n",
    "            X_sample, y_sample, sample_indices = self._bootstrap_sample(X, y)\n",
    "            \n",
    "            # Get random features\n",
    "            feature_indices = self._get_random_features(n_features)\n",
    "            feature_usage[feature_indices] += 1\n",
    "            \n",
    "            # Create and train tree with random features\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=self.random_state + i if self.random_state else None\n",
    "            )\n",
    "            \n",
    "            # Train tree on selected features only\n",
    "            tree.fit(X_sample[:, feature_indices], y_sample)\n",
    "            \n",
    "            # Store tree and its feature indices\n",
    "            self.trees.append({\n",
    "                'tree': tree,\n",
    "                'features': feature_indices,\n",
    "                'sample_indices': sample_indices\n",
    "            })\n",
    "        \n",
    "        # Calculate simple feature importance based on usage\n",
    "        self.feature_importances_ = feature_usage / self.n_estimators\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using majority voting\"\"\"\n",
    "        X = np.array(X)\n",
    "        predictions = []\n",
    "        \n",
    "        for tree_info in self.trees:\n",
    "            tree = tree_info['tree']\n",
    "            features = tree_info['features']\n",
    "            pred = tree.predict(X[:, features])\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Majority voting\n",
    "        predictions = np.array(predictions).T\n",
    "        return np.array([np.bincount(row).argmax() for row in predictions])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities\"\"\"\n",
    "        X = np.array(X)\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = 2  # Simplified for binary classification\n",
    "        \n",
    "        probabilities = np.zeros((n_samples, n_classes))\n",
    "        \n",
    "        for tree_info in self.trees:\n",
    "            tree = tree_info['tree']\n",
    "            features = tree_info['features']\n",
    "            proba = tree.predict_proba(X[:, features])\n",
    "            probabilities += proba\n",
    "        \n",
    "        return probabilities / self.n_estimators\n",
    "\n",
    "# Test our implementation\n",
    "print(\"ðŸŒ² Testing Random Forest from Scratch\")\n",
    "\n",
    "# Use only first 2 features for simplicity\n",
    "X_simple = X_cls[:, :2]\n",
    "y_simple = y_cls\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y_simple, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train our Random Forest\n",
    "rf_scratch = RandomForestScratch(n_estimators=10, max_depth=3, random_state=42)\n",
    "rf_scratch.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scratch = rf_scratch.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy (Scratch): {accuracy_score(y_test, y_pred_scratch):.3f}\")\n",
    "print(f\"Feature Importances: {rf_scratch.feature_importances_}\")\n",
    "\n",
    "# Compare with single decision tree\n",
    "tree_single = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_single.fit(X_train, y_train)\n",
    "y_pred_single = tree_single.predict(X_test)\n",
    "\n",
    "print(f\"Single Tree Accuracy: {accuracy_score(y_test, y_pred_single):.3f}\")\n",
    "print(f\"Random Forest shows {'improvement' if accuracy_score(y_test, y_pred_scratch) > accuracy_score(y_test, y_pred_single) else 'similar performance'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4f19e",
   "metadata": {},
   "source": [
    "## **ðŸ› ï¸ 5. Scikit-learn Implementation - Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with Wine dataset\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# Create Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    oob_score=True  # Enable out-of-bag scoring\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_clf.fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_clf.predict(X_train_wine)\n",
    "y_test_pred = rf_clf.predict(X_test_wine)\n",
    "y_test_proba = rf_clf.predict_proba(X_test_wine)\n",
    "\n",
    "print(\"ðŸŽ¯ Random Forest Classification Results:\")\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train_wine, y_train_pred):.3f}\")\n",
    "print(f\"Testing Accuracy:  {accuracy_score(y_test_wine, y_test_pred):.3f}\")\n",
    "print(f\"OOB Score:         {rf_clf.oob_score_:.3f}\")\n",
    "\n",
    "print(f\"\\nPrecision: {precision_score(y_test_wine, y_test_pred, average='weighted'):.3f}\")\n",
    "print(f\"Recall:    {recall_score(y_test_wine, y_test_pred, average='weighted'):.3f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test_wine, y_test_pred, average='weighted'):.3f}\")\n",
    "\n",
    "# Compare with single Decision Tree\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "tree_clf.fit(X_train_wine, y_train_wine)\n",
    "tree_test_pred = tree_clf.predict(X_test_wine)\n",
    "\n",
    "print(f\"\\nðŸŒ³ Single Decision Tree Accuracy: {accuracy_score(y_test_wine, tree_test_pred):.3f}\")\n",
    "print(f\"ðŸŒ² Random Forest Improvement: {accuracy_score(y_test_wine, y_test_pred) - accuracy_score(y_test_wine, tree_test_pred):+.3f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Top 10 Feature Importances:\")\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': wine.feature_names,\n",
    "    'Importance': rf_clf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test_wine, y_test_pred, target_names=wine.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38b984",
   "metadata": {},
   "source": [
    "## **ðŸ“ˆ 6. Scikit-learn Implementation - Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with synthetic dataset\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create Random Forest regressor\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_reg = rf_reg.predict(X_train_reg)\n",
    "y_test_pred_reg = rf_reg.predict(X_test_reg)\n",
    "\n",
    "print(\"ðŸ“ˆ Random Forest Regression Results:\")\n",
    "print(f\"Training RÂ² Score: {r2_score(y_train_reg, y_train_pred_reg):.3f}\")\n",
    "print(f\"Testing RÂ² Score:  {r2_score(y_test_reg, y_test_pred_reg):.3f}\")\n",
    "print(f\"OOB Score:         {rf_reg.oob_score_:.3f}\")\n",
    "\n",
    "print(f\"Training RMSE:     {np.sqrt(mean_squared_error(y_train_reg, y_train_pred_reg)):.3f}\")\n",
    "print(f\"Testing RMSE:      {np.sqrt(mean_squared_error(y_test_reg, y_test_pred_reg)):.3f}\")\n",
    "print(f\"Testing MAE:       {mean_absolute_error(y_test_reg, y_test_pred_reg):.3f}\")\n",
    "\n",
    "# Compare with single Decision Tree\n",
    "tree_reg = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "tree_reg.fit(X_train_reg, y_train_reg)\n",
    "tree_test_pred_reg = tree_reg.predict(X_test_reg)\n",
    "\n",
    "print(f\"\\nðŸŒ³ Single Decision Tree RÂ²: {r2_score(y_test_reg, tree_test_pred_reg):.3f}\")\n",
    "print(f\"ðŸŒ² Random Forest Improvement: {r2_score(y_test_reg, y_test_pred_reg) - r2_score(y_test_reg, tree_test_pred_reg):+.3f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Feature Importances (Regression):\")\n",
    "reg_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names_reg,\n",
    "    'Importance': rf_reg.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(reg_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31d3ab",
   "metadata": {},
   "source": [
    "## **ðŸ“Š 7. Comprehensive Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305acfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "# 1. Feature Importance Comparison (Classification)\n",
    "top_features = feature_importance_df.head(8)\n",
    "axes[0, 0].barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "axes[0, 0].set_xlabel('Importance')\n",
    "axes[0, 0].set_title('Top 8 Feature Importances (Wine)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_test_wine, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],\n",
    "            xticklabels=wine.target_names, yticklabels=wine.target_names)\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Actual')\n",
    "axes[0, 1].set_title('Confusion Matrix')\n",
    "\n",
    "# 3. OOB Error vs Number of Trees\n",
    "n_estimators_range = range(10, 101, 10)\n",
    "oob_errors = []\n",
    "\n",
    "for n_est in n_estimators_range:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=n_est, random_state=42, oob_score=True)\n",
    "    rf_temp.fit(X_train_wine, y_train_wine)\n",
    "    oob_errors.append(1 - rf_temp.oob_score_)\n",
    "\n",
    "axes[0, 2].plot(n_estimators_range, oob_errors, 'b-', marker='o')\n",
    "axes[0, 2].set_xlabel('Number of Trees')\n",
    "axes[0, 2].set_ylabel('OOB Error')\n",
    "axes[0, 2].set_title('OOB Error vs Number of Trees')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Individual Tree Predictions vs Ensemble\n",
    "# Show predictions for first 50 test samples\n",
    "n_show = 50\n",
    "individual_preds = []\n",
    "for estimator in rf_clf.estimators_[:10]:  # Show first 10 trees\n",
    "    pred = estimator.predict(X_test_wine[:n_show])\n",
    "    individual_preds.append(pred)\n",
    "\n",
    "individual_preds = np.array(individual_preds)\n",
    "ensemble_pred = rf_clf.predict(X_test_wine[:n_show])\n",
    "\n",
    "axes[1, 0].imshow(individual_preds, aspect='auto', cmap='Set1', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Test Samples')\n",
    "axes[1, 0].set_ylabel('Individual Trees')\n",
    "axes[1, 0].set_title('Individual Tree Predictions')\n",
    "\n",
    "# 5. Regression: True vs Predicted\n",
    "axes[1, 1].scatter(y_test_reg, y_test_pred_reg, alpha=0.6, color='orange')\n",
    "axes[1, 1].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "                [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_xlabel('True Values')\n",
    "axes[1, 1].set_ylabel('Predicted Values')\n",
    "axes[1, 1].set_title('Regression: True vs Predicted')\n",
    "\n",
    "# 6. Prediction Intervals (using tree predictions)\n",
    "tree_predictions = np.array([tree.predict(X_test_reg) for tree in rf_reg.estimators_])\n",
    "pred_mean = np.mean(tree_predictions, axis=0)\n",
    "pred_std = np.std(tree_predictions, axis=0)\n",
    "\n",
    "# Sort by true values for better visualization\n",
    "sort_idx = np.argsort(y_test_reg)\n",
    "axes[1, 2].fill_between(range(len(y_test_reg)), \n",
    "                       (pred_mean - 2*pred_std)[sort_idx],\n",
    "                       (pred_mean + 2*pred_std)[sort_idx],\n",
    "                       alpha=0.3, color='lightblue', label='95% Prediction Interval')\n",
    "axes[1, 2].plot(y_test_reg[sort_idx], 'o', alpha=0.6, color='red', label='True Values')\n",
    "axes[1, 2].plot(pred_mean[sort_idx], '-', color='blue', label='RF Prediction')\n",
    "axes[1, 2].set_xlabel('Sample Index (sorted)')\n",
    "axes[1, 2].set_ylabel('Target Value')\n",
    "axes[1, 2].set_title('Prediction Intervals')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "# 7. Cross-validation scores\n",
    "cv_scores = cross_val_score(rf_clf, X_wine, y_wine, cv=5, scoring='accuracy')\n",
    "axes[2, 0].bar(range(1, 6), cv_scores, color='green', alpha=0.7)\n",
    "axes[2, 0].axhline(cv_scores.mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {cv_scores.mean():.3f}')\n",
    "axes[2, 0].set_xlabel('Fold')\n",
    "axes[2, 0].set_ylabel('Accuracy')\n",
    "axes[2, 0].set_title('Cross-Validation Scores')\n",
    "axes[2, 0].legend()\n",
    "\n",
    "# 8. Learning Curve: Performance vs Training Set Size\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    n_samples = int(train_size * len(X_train_wine))\n",
    "    rf_temp = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    rf_temp.fit(X_train_wine[:n_samples], y_train_wine[:n_samples])\n",
    "    \n",
    "    train_score = rf_temp.score(X_train_wine[:n_samples], y_train_wine[:n_samples])\n",
    "    test_score = rf_temp.score(X_test_wine, y_test_wine)\n",
    "    \n",
    "    train_scores_mean.append(train_score)\n",
    "    test_scores_mean.append(test_score)\n",
    "\n",
    "axes[2, 1].plot(train_sizes, train_scores_mean, 'o-', label='Training Score', color='blue')\n",
    "axes[2, 1].plot(train_sizes, test_scores_mean, 'o-', label='Validation Score', color='red')\n",
    "axes[2, 1].set_xlabel('Training Set Size (fraction)')\n",
    "axes[2, 1].set_ylabel('Accuracy')\n",
    "axes[2, 1].set_title('Learning Curve')\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Feature Importance Distribution\n",
    "axes[2, 2].hist(rf_clf.feature_importances_, bins=10, alpha=0.7, color='purple')\n",
    "axes[2, 2].set_xlabel('Feature Importance')\n",
    "axes[2, 2].set_ylabel('Number of Features')\n",
    "axes[2, 2].set_title('Distribution of Feature Importances')\n",
    "axes[2, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“Š Cross-Validation Results:\")\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9843f95",
   "metadata": {},
   "source": [
    "## **âš–ï¸ 8. Bias-Variance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20682df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze bias-variance tradeoff with number of estimators\n",
    "print(\"ðŸŽ¯ Bias-Variance Analysis\")\n",
    "\n",
    "n_estimators_range = [1, 5, 10, 25, 50, 100, 200]\n",
    "n_iterations = 20\n",
    "bias_values = []\n",
    "variance_values = []\n",
    "mse_values = []\n",
    "\n",
    "# Create a fixed test set\n",
    "X_fixed_test = X_test_wine[:20]  # Use smaller set for computation\n",
    "y_fixed_test = y_test_wine[:20]\n",
    "\n",
    "for n_est in n_estimators_range:\n",
    "    predictions = []\n",
    "    \n",
    "    # Run multiple iterations with different random states\n",
    "    for iteration in range(n_iterations):\n",
    "        # Create bootstrap sample for training\n",
    "        indices = np.random.choice(len(X_train_wine), size=len(X_train_wine), replace=True)\n",
    "        X_bootstrap = X_train_wine[indices]\n",
    "        y_bootstrap = y_train_wine[indices]\n",
    "        \n",
    "        # Train Random Forest\n",
    "        rf_temp = RandomForestClassifier(n_estimators=n_est, random_state=iteration)\n",
    "        rf_temp.fit(X_bootstrap, y_bootstrap)\n",
    "        \n",
    "        # Get predictions (convert to numeric for bias-variance calculation)\n",
    "        pred = rf_temp.predict(X_fixed_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Calculate mean prediction across all iterations\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # Calculate biasÂ² (squared difference between mean prediction and true value)\n",
    "    bias_squared = np.mean((mean_prediction - y_fixed_test) ** 2)\n",
    "    \n",
    "    # Calculate variance (average squared difference from mean prediction)\n",
    "    variance = np.mean(np.var(predictions, axis=0))\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean([np.mean((pred - y_fixed_test) ** 2) for pred in predictions])\n",
    "    \n",
    "    bias_values.append(bias_squared)\n",
    "    variance_values.append(variance)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "# Plot bias-variance decomposition\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(n_estimators_range, bias_values, 'r-o', label='BiasÂ²', linewidth=2)\n",
    "plt.plot(n_estimators_range, variance_values, 'b-o', label='Variance', linewidth=2)\n",
    "plt.plot(n_estimators_range, mse_values, 'g-o', label='Total Error', linewidth=2)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Bias-Variance Decomposition')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "\n",
    "# Analyze effect of max_features\n",
    "max_features_options = [1, 2, 3, 'sqrt', 'log2', None]\n",
    "max_features_scores = []\n",
    "\n",
    "for max_feat in max_features_options:\n",
    "    rf_temp = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_features=max_feat, \n",
    "        random_state=42,\n",
    "        oob_score=True\n",
    "    )\n",
    "    rf_temp.fit(X_train_wine, y_train_wine)\n",
    "    max_features_scores.append(rf_temp.oob_score_)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(range(len(max_features_options)), max_features_scores, \n",
    "        color=['red', 'blue', 'green', 'orange', 'purple', 'brown'])\n",
    "plt.xlabel('Max Features')\n",
    "plt.ylabel('OOB Score')\n",
    "plt.title('Effect of max_features Parameter')\n",
    "plt.xticks(range(len(max_features_options)), \n",
    "          [str(x) for x in max_features_options], rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation curve for max_depth\n",
    "train_scores_depth, test_scores_depth = validation_curve(\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42), \n",
    "    X_wine, y_wine,\n",
    "    param_name='max_depth', \n",
    "    param_range=range(1, 21),\n",
    "    cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, 21), train_scores_depth.mean(axis=1), 'o-', label='Training', color='blue')\n",
    "plt.plot(range(1, 21), test_scores_depth.mean(axis=1), 'o-', label='Validation', color='red')\n",
    "plt.fill_between(range(1, 21), \n",
    "                 train_scores_depth.mean(axis=1) - train_scores_depth.std(axis=1),\n",
    "                 train_scores_depth.mean(axis=1) + train_scores_depth.std(axis=1),\n",
    "                 alpha=0.1, color='blue')\n",
    "plt.fill_between(range(1, 21), \n",
    "                 test_scores_depth.mean(axis=1) - test_scores_depth.std(axis=1),\n",
    "                 test_scores_depth.mean(axis=1) + test_scores_depth.std(axis=1),\n",
    "                 alpha=0.1, color='red')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Curve: Max Depth')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š Max Features Analysis:\")\n",
    "for i, (feat, score) in enumerate(zip(max_features_options, max_features_scores)):\n",
    "    print(f\"{feat}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5acdccd",
   "metadata": {},
   "source": [
    "## **ðŸŽ›ï¸ 9. Hyperparameter Tuning and Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df762336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "print(\"ðŸŽ›ï¸ Hyperparameter Tuning for Random Forest\")\n",
    "\n",
    "# Define parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Use a smaller dataset for faster computation\n",
    "X_sample, _, y_sample, _ = train_test_split(X_wine, y_wine, train_size=0.3, random_state=42)\n",
    "\n",
    "print(\"ðŸ” Grid Search (limited parameters for demo)\")\n",
    "# Limited grid search for demonstration\n",
    "limited_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    limited_param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_sample, y_sample)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Random Search (more efficient for larger parameter spaces)\n",
    "print(\"\\nðŸŽ² Random Search\")\n",
    "from scipy.stats import randint\n",
    "\n",
    "random_param_dist = {\n",
    "    'n_estimators': randint(50, 301),\n",
    "    'max_depth': randint(3, 21),\n",
    "    'min_samples_split': randint(2, 21),\n",
    "    'min_samples_leaf': randint(1, 11),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    random_param_dist,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_sample, y_sample)\n",
    "\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best CV score: {random_search.best_score_:.3f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf = RandomForestClassifier(**random_search.best_params_, random_state=42)\n",
    "best_rf.fit(X_train_wine, y_train_wine)\n",
    "best_predictions = best_rf.predict(X_test_wine)\n",
    "\n",
    "print(f\"\\nðŸ† Final Model Performance:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_wine, best_predictions):.3f}\")\n",
    "\n",
    "# Compare with default parameters\n",
    "default_rf = RandomForestClassifier(random_state=42)\n",
    "default_rf.fit(X_train_wine, y_train_wine)\n",
    "default_predictions = default_rf.predict(X_test_wine)\n",
    "\n",
    "print(f\"Default RF Accuracy: {accuracy_score(y_test_wine, default_predictions):.3f}\")\n",
    "print(f\"Improvement: {accuracy_score(y_test_wine, best_predictions) - accuracy_score(y_test_wine, default_predictions):+.3f}\")\n",
    "\n",
    "# Visualize parameter importance\n",
    "feature_importance_comparison = pd.DataFrame({\n",
    "    'Feature': wine.feature_names,\n",
    "    'Default_RF': default_rf.feature_importances_,\n",
    "    'Tuned_RF': best_rf.feature_importances_\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "x = np.arange(len(wine.feature_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, default_rf.feature_importances_, width, \n",
    "        label='Default RF', alpha=0.7, color='lightblue')\n",
    "plt.bar(x + width/2, best_rf.feature_importances_, width, \n",
    "        label='Tuned RF', alpha=0.7, color='lightcoral')\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance: Default vs Tuned Random Forest')\n",
    "plt.xticks(x, wine.feature_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd8f0a",
   "metadata": {},
   "source": [
    "## **ðŸ“Š 10. Out-of-Bag (OOB) Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Out-of-Bag (OOB) Analysis\")\n",
    "\n",
    "# Create Random Forest with OOB scoring enabled\n",
    "rf_oob = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    oob_score=True,\n",
    "    warm_start=True  # Allow adding more trees later\n",
    ")\n",
    "\n",
    "# Track OOB score as we add more trees\n",
    "oob_scores = []\n",
    "n_trees_range = range(10, 101, 10)\n",
    "\n",
    "for n_trees in n_trees_range:\n",
    "    rf_oob.n_estimators = n_trees\n",
    "    rf_oob.fit(X_train_wine, y_train_wine)\n",
    "    oob_scores.append(rf_oob.oob_score_)\n",
    "\n",
    "# Compare OOB score with test score\n",
    "test_scores = []\n",
    "for n_trees in n_trees_range:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
    "    rf_temp.fit(X_train_wine, y_train_wine)\n",
    "    test_scores.append(rf_temp.score(X_test_wine, y_test_wine))\n",
    "\n",
    "# Plot OOB vs Test scores\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(n_trees_range, oob_scores, 'b-o', label='OOB Score', linewidth=2)\n",
    "plt.plot(n_trees_range, test_scores, 'r-o', label='Test Score', linewidth=2)\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('OOB Score vs Test Score')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"Final OOB Score: {rf_oob.oob_score_:.3f}\")\n",
    "print(f\"Final Test Score: {rf_oob.score(X_test_wine, y_test_wine):.3f}\")\n",
    "print(f\"Difference: {abs(rf_oob.oob_score_ - rf_oob.score(X_test_wine, y_test_wine)):.3f}\")\n",
    "\n",
    "# OOB predictions and decision function\n",
    "oob_predictions = rf_oob.oob_decision_function_\n",
    "oob_predicted_classes = np.argmax(oob_predictions, axis=1)\n",
    "\n",
    "# Compare OOB predictions with true labels\n",
    "oob_accuracy = accuracy_score(y_train_wine, oob_predicted_classes)\n",
    "print(f\"OOB Prediction Accuracy: {oob_accuracy:.3f}\")\n",
    "\n",
    "# Visualize OOB prediction confidence\n",
    "plt.subplot(1, 3, 2)\n",
    "max_probs = np.max(oob_predictions, axis=1)\n",
    "plt.hist(max_probs, bins=20, alpha=0.7, color='green')\n",
    "plt.xlabel('Maximum OOB Probability')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Distribution of OOB Prediction Confidence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Analyze OOB errors\n",
    "oob_errors = (oob_predicted_classes != y_train_wine)\n",
    "error_probs = max_probs[oob_errors]\n",
    "correct_probs = max_probs[~oob_errors]\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(correct_probs, bins=15, alpha=0.5, label='Correct Predictions', color='green')\n",
    "plt.hist(error_probs, bins=15, alpha=0.5, label='Incorrect Predictions', color='red')\n",
    "plt.xlabel('Maximum OOB Probability')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Confidence: Correct vs Incorrect Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average confidence for correct predictions: {np.mean(correct_probs):.3f}\")\n",
    "print(f\"Average confidence for incorrect predictions: {np.mean(error_probs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568b27f",
   "metadata": {},
   "source": [
    "## **âœ… 11. Advantages and Disadvantages**\n",
    "\n",
    "### **Advantages:** âœ…\n",
    "\n",
    "1. **Reduced Overfitting**: Ensemble reduces variance compared to single trees\n",
    "2. **High Accuracy**: Generally achieves better performance than single models\n",
    "3. **Feature Importance**: Provides robust feature importance scores\n",
    "4. **Handles Missing Values**: Can work with incomplete data\n",
    "5. **Out-of-Bag Validation**: Built-in cross-validation through OOB scoring\n",
    "6. **Parallel Training**: Trees can be trained independently\n",
    "7. **Robust to Outliers**: Averaging reduces impact of outliers\n",
    "8. **No Data Preprocessing**: Works with raw numerical and categorical data\n",
    "9. **Handles Large Datasets**: Scales well with data size\n",
    "10. **Stable**: Less sensitive to small changes in data\n",
    "\n",
    "### **Disadvantages:** âŒ\n",
    "\n",
    "1. **Less Interpretable**: Harder to interpret than single decision trees\n",
    "2. **Memory Usage**: Requires more memory to store multiple trees\n",
    "3. **Overfitting with Noise**: Can still overfit with very noisy data\n",
    "4. **Biased Feature Selection**: Still biased toward features with more levels\n",
    "5. **Prediction Speed**: Slower prediction than single trees\n",
    "6. **Black Box**: Less transparent than single tree models\n",
    "7. **Hyperparameter Tuning**: More parameters to tune than simple models\n",
    "\n",
    "### **When to Use Random Forest:** ðŸŽ¯\n",
    "\n",
    "- **High Accuracy Needed**: When you prioritize performance over interpretability\n",
    "- **Mixed Data Types**: When you have both numerical and categorical features\n",
    "- **Feature Selection**: When you need automatic feature importance ranking\n",
    "- **Robust Models**: When you need stable, reliable predictions\n",
    "- **Baseline Models**: As a strong baseline for more complex models\n",
    "- **Limited Data Preprocessing**: When you want minimal data preparation\n",
    "\n",
    "### **When NOT to Use:** âš ï¸\n",
    "\n",
    "- **Simple Linear Relationships**: When relationships are primarily linear\n",
    "- **High Interpretability Required**: When you need to explain every decision\n",
    "- **Real-time Predictions**: When prediction speed is critical\n",
    "- **Memory Constraints**: When memory usage is a major concern\n",
    "- **Very Small Datasets**: When you have very limited training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c7c63",
   "metadata": {},
   "source": [
    "## **ðŸ†š 12. Random Forest vs Decision Trees Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison between Random Forest and Decision Trees\n",
    "print(\"ðŸ†š Random Forest vs Decision Trees Comparison\")\n",
    "\n",
    "# Create different models for comparison\n",
    "models = {\n",
    "    'Decision Tree (Deep)': DecisionTreeClassifier(random_state=42),\n",
    "    'Decision Tree (Pruned)': DecisionTreeClassifier(max_depth=5, min_samples_split=10, random_state=42),\n",
    "    'Random Forest (50 trees)': RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    'Random Forest (100 trees)': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Compare performance across different metrics\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_wine, y_train_wine)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test_wine)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_wine, y_pred)\n",
    "    precision = precision_score(y_test_wine, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_wine, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_wine, y_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_score = cross_val_score(model, X_wine, y_wine, cv=5).mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'CV Score': cv_score\n",
    "    })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(\"ðŸ“Š Model Comparison:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Performance metrics comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Score']\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "\n",
    "for i, metric in enumerate(metrics[:4]):\n",
    "    ax = axes[i//2, i%2]\n",
    "    bars = ax.bar(x_pos, comparison_df[metric], \n",
    "                  color=['red', 'orange', 'lightblue', 'blue'], alpha=0.7)\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3),  # 3 points vertical offset\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stability Analysis: Train models multiple times with different random states\n",
    "print(\"\\nðŸŽ² Stability Analysis:\")\n",
    "stability_results = []\n",
    "\n",
    "for random_state in range(10):\n",
    "    dt_scores = []\n",
    "    rf_scores = []\n",
    "    \n",
    "    # Create bootstrap samples\n",
    "    for _ in range(5):\n",
    "        indices = np.random.choice(len(X_wine), size=len(X_wine), replace=True)\n",
    "        X_bootstrap = X_wine[indices]\n",
    "        y_bootstrap = y_wine[indices]\n",
    "        \n",
    "        # Split bootstrap sample\n",
    "        X_train_boot, X_test_boot, y_train_boot, y_test_boot = train_test_split(\n",
    "            X_bootstrap, y_bootstrap, test_size=0.3, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train models\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        rf = RandomForestClassifier(n_estimators=50, random_state=random_state)\n",
    "        \n",
    "        dt.fit(X_train_boot, y_train_boot)\n",
    "        rf.fit(X_train_boot, y_train_boot)\n",
    "        \n",
    "        dt_scores.append(dt.score(X_test_boot, y_test_boot))\n",
    "        rf_scores.append(rf.score(X_test_boot, y_test_boot))\n",
    "    \n",
    "    stability_results.append({\n",
    "        'DT_mean': np.mean(dt_scores),\n",
    "        'DT_std': np.std(dt_scores),\n",
    "        'RF_mean': np.mean(rf_scores),\n",
    "        'RF_std': np.std(rf_scores)\n",
    "    })\n",
    "\n",
    "stability_df = pd.DataFrame(stability_results)\n",
    "\n",
    "print(f\"Decision Tree - Mean Accuracy: {stability_df['DT_mean'].mean():.3f} Â± {stability_df['DT_std'].mean():.3f}\")\n",
    "print(f\"Random Forest - Mean Accuracy: {stability_df['RF_mean'].mean():.3f} Â± {stability_df['RF_std'].mean():.3f}\")\n",
    "print(f\"Random Forest shows {'higher' if stability_df['RF_mean'].mean() > stability_df['DT_mean'].mean() else 'lower'} accuracy\")\n",
    "print(f\"Random Forest shows {'lower' if stability_df['RF_std'].mean() < stability_df['DT_std'].mean() else 'higher'} variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac934491",
   "metadata": {},
   "source": [
    "## **ðŸ” 13. Real-World Example: Medical Diagnosis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4aab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset for medical diagnosis example\n",
    "print(\"ðŸ¥ Medical Diagnosis Example: Breast Cancer Classification\")\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target\n",
    "\n",
    "print(f\"Dataset: {cancer.data.shape[0]} patients, {cancer.data.shape[1]} features\")\n",
    "print(f\"Classes: {cancer.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y_cancer)}\")\n",
    "\n",
    "# Create feature DataFrame\n",
    "cancer_df = pd.DataFrame(X_cancer, columns=cancer.feature_names)\n",
    "cancer_df['diagnosis'] = y_cancer\n",
    "\n",
    "print(\"\\nFirst 5 patients:\")\n",
    "display(cancer_df.head())\n",
    "\n",
    "# Split the data\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# Train Random Forest for medical diagnosis\n",
    "medical_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "medical_rf.fit(X_train_cancer, y_train_cancer)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cancer = medical_rf.predict(X_test_cancer)\n",
    "y_proba_cancer = medical_rf.predict_proba(X_test_cancer)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Medical Diagnosis Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_cancer, y_pred_cancer):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test_cancer, y_pred_cancer):.3f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_score(y_test_cancer, y_pred_cancer):.3f}\")\n",
    "print(f\"Specificity: {confusion_matrix(y_test_cancer, y_pred_cancer)[0,0] / (confusion_matrix(y_test_cancer, y_pred_cancer)[0,0] + confusion_matrix(y_test_cancer, y_pred_cancer)[0,1]):.3f}\")\n",
    "\n",
    "# Feature importance for medical interpretation\n",
    "medical_importance = pd.DataFrame({\n",
    "    'Feature': cancer.feature_names,\n",
    "    'Importance': medical_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Top 10 Most Important Features for Diagnosis:\")\n",
    "print(medical_importance.head(10))\n",
    "\n",
    "# Visualize medical results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Feature importance\n",
    "top_features = medical_importance.head(15)\n",
    "axes[0, 0].barh(top_features['Feature'], top_features['Importance'])\n",
    "axes[0, 0].set_xlabel('Importance')\n",
    "axes[0, 0].set_title('Top 15 Features for Cancer Diagnosis')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Confusion matrix\n",
    "cm_cancer = confusion_matrix(y_test_cancer, y_pred_cancer)\n",
    "sns.heatmap(cm_cancer, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],\n",
    "            xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Actual')\n",
    "axes[0, 1].set_title('Confusion Matrix - Cancer Diagnosis')\n",
    "\n",
    "# 3. Prediction confidence distribution\n",
    "axes[1, 0].hist(y_proba_cancer[y_test_cancer == 0, 0], bins=20, alpha=0.5, \n",
    "                label='Malignant (True)', color='red')\n",
    "axes[1, 0].hist(y_proba_cancer[y_test_cancer == 1, 1], bins=20, alpha=0.5, \n",
    "                label='Benign (True)', color='green')\n",
    "axes[1, 0].set_xlabel('Prediction Confidence')\n",
    "axes[1, 0].set_ylabel('Number of Patients')\n",
    "axes[1, 0].set_title('Prediction Confidence Distribution')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test_cancer, y_proba_cancer[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1, 1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1, 1].set_xlim([0.0, 1.0])\n",
    "axes[1, 1].set_ylim([0.0, 1.05])\n",
    "axes[1, 1].set_xlabel('False Positive Rate')\n",
    "axes[1, 1].set_ylabel('True Positive Rate')\n",
    "axes[1, 1].set_title('ROC Curve - Cancer Diagnosis')\n",
    "axes[1, 1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clinical interpretation\n",
    "print(\"\\nðŸ¥ Clinical Interpretation:\")\n",
    "print(\"Most important features for cancer diagnosis:\")\n",
    "for i, (_, row) in enumerate(medical_importance.head(5).iterrows()):\n",
    "    print(f\"{i+1}. {row['Feature']}: {row['Importance']:.3f}\")\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"â€¢ High accuracy ({accuracy_score(y_test_cancer, y_pred_cancer):.1%}) suitable for medical screening\")\n",
    "print(f\"â€¢ High sensitivity ({recall_score(y_test_cancer, y_pred_cancer):.1%}) - good at detecting cancer\")\n",
    "print(f\"â€¢ ROC-AUC of {roc_auc:.3f} indicates excellent diagnostic ability\")\n",
    "print(f\"â€¢ Feature importance helps doctors understand key diagnostic indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9118dc1",
   "metadata": {},
   "source": [
    "## **ðŸ“ 14. Summary and Key Takeaways**\n",
    "\n",
    "### **Random Forest in a Nutshell:** ðŸŒ°\n",
    "\n",
    "Random Forest is a powerful ensemble method that combines multiple decision trees using bootstrap sampling and random feature selection to create more accurate and robust predictions than individual decision trees.\n",
    "\n",
    "### **Key Concepts Learned:** ðŸ’¡\n",
    "\n",
    "1. **Ensemble Learning**: Combining multiple weak learners creates a strong learner\n",
    "2. **Bootstrap Aggregating**: Reduces variance through averaging\n",
    "3. **Random Feature Selection**: Reduces correlation between trees\n",
    "4. **Out-of-Bag Validation**: Built-in cross-validation without separate test set\n",
    "5. **Feature Importance**: Robust feature ranking across multiple trees\n",
    "6. **Bias-Variance Tradeoff**: RF reduces variance while maintaining low bias\n",
    "\n",
    "### **Key Hyperparameters:** ðŸŽ›ï¸\n",
    "\n",
    "1. **n_estimators**: Number of trees (more trees = better performance, diminishing returns)\n",
    "2. **max_features**: Number of features per split ('sqrt' often works well)\n",
    "3. **max_depth**: Maximum tree depth (controls overfitting)\n",
    "4. **min_samples_split**: Minimum samples to split a node\n",
    "5. **min_samples_leaf**: Minimum samples in leaf nodes\n",
    "6. **oob_score**: Enable out-of-bag scoring for validation\n",
    "\n",
    "### **Best Practices:** ðŸŽ¯\n",
    "\n",
    "1. **Start with Defaults**: Random Forest works well out-of-the-box\n",
    "2. **Use OOB Score**: Leverage built-in validation for model selection\n",
    "3. **Feature Importance**: Use for feature selection and interpretation\n",
    "4. **Balance Trees**: More trees generally better, but diminishing returns after ~100\n",
    "5. **Cross-Validate**: Always validate performance with cross-validation\n",
    "6. **Consider Memory**: More trees = more memory usage\n",
    "\n",
    "### **Performance Tips:** âš¡\n",
    "\n",
    "- **Parallel Processing**: Set `n_jobs=-1` for faster training\n",
    "- **Warm Start**: Use `warm_start=True` to add trees incrementally\n",
    "- **Feature Engineering**: Good features still matter for RF performance\n",
    "- **Class Imbalance**: Use `class_weight='balanced'` for imbalanced datasets\n",
    "\n",
    "### **When to Use Random Forest:** âœ…\n",
    "\n",
    "- **Tabular Data**: Excellent for structured/tabular datasets\n",
    "- **Mixed Data Types**: Handles numerical and categorical features\n",
    "- **Feature Selection**: When you need feature importance\n",
    "- **Robust Predictions**: When you need stable, reliable models\n",
    "- **Baseline Models**: Strong baseline for comparison\n",
    "- **Interpretability**: When you need some interpretability (via feature importance)\n",
    "\n",
    "### **Comparison with Other Methods:**\n",
    "\n",
    "| Method | Interpretability | Accuracy | Training Speed | Prediction Speed |\n",
    "|--------|------------------|-----------|----------------|------------------|\n",
    "| Decision Tree | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |\n",
    "| Random Forest | â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |\n",
    "| Linear Models | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |\n",
    "\n",
    "### **Next Steps:** ðŸš€\n",
    "\n",
    "- **XGBoost**: Learn gradient boosting for even better performance\n",
    "- **Feature Engineering**: Improve your features for better RF performance\n",
    "- **Hyperparameter Tuning**: Use GridSearch or Bayesian optimization\n",
    "- **Ensemble Methods**: Combine RF with other algorithms\n",
    "- **Deep Learning**: Explore neural networks for complex patterns\n",
    "\n",
    "Random Forest is often the \"Swiss Army knife\" of machine learning - reliable, robust, and effective across many different types of problems! ðŸŒ²âœ¨"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
